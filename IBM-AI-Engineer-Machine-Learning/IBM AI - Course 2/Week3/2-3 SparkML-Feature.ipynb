{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SparkML-Feature.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM9xP2CzFUkumXZzIB+ndmF"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"0KhDBqBfgzpG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"9ccc893f-e8ea-489e-a624-2118e024d702","executionInfo":{"status":"ok","timestamp":1585556261123,"user_tz":-480,"elapsed":72910,"user":{"displayName":"Harunobu Ishii","photoUrl":"","userId":"07995597585064114670"}}},"source":["!pip install --upgrade pip\n","# 各ライブラリインストール\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://apache.osuosl.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n","!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# 環境変数設定\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n","\n","# findsparkで環境設定\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pip\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 2.8MB/s \n","\u001b[?25hInstalling collected packages: pip\n","  Found existing installation: pip 19.3.1\n","    Uninstalling pip-19.3.1:\n","      Successfully uninstalled pip-19.3.1\n","Successfully installed pip-20.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VbdJALBog1Ee","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"523a7eba-a452-4007-c315-f31df959cb23","executionInfo":{"status":"ok","timestamp":1585556269092,"user_tz":-480,"elapsed":7429,"user":{"displayName":"Harunobu Ishii","photoUrl":"","userId":"07995597585064114670"}}},"source":["#Delete from previous runs\n","!rm -f hmp.parquet*\n","\n","#Download\n","!wget https://github.com/IBM/coursera/raw/master/hmp.parquet\n","\n","#Create a dataframe \n","df = spark.read.parquet('hmp.parquet')\n","\n","#Register a corresponding query table\n","df.createOrReplaceTempView('df')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-03-30 08:17:45--  https://github.com/IBM/coursera/raw/master/hmp.parquet\n","Resolving github.com (github.com)... 140.82.112.4\n","Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://github.com/IBM/skillsnetwork/raw/master/hmp.parquet [following]\n","--2020-03-30 08:17:45--  https://github.com/IBM/skillsnetwork/raw/master/hmp.parquet\n","Reusing existing connection to github.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/IBM/skillsnetwork/master/hmp.parquet [following]\n","--2020-03-30 08:17:45--  https://raw.githubusercontent.com/IBM/skillsnetwork/master/hmp.parquet\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 932997 (911K) [application/octet-stream]\n","Saving to: ‘hmp.parquet’\n","\n","hmp.parquet         100%[===================>] 911.13K  --.-KB/s    in 0.09s   \n","\n","2020-03-30 08:17:46 (10.2 MB/s) - ‘hmp.parquet’ saved [932997/932997]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88bzNAq9nmAU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":459},"outputId":"6cd20e53-182c-47b3-fc25-838ab63aff02","executionInfo":{"status":"ok","timestamp":1585557962349,"user_tz":-480,"elapsed":2277,"user":{"displayName":"Harunobu Ishii","photoUrl":"","userId":"07995597585064114670"}}},"source":["df.show()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["+---+---+---+--------------------+-----------+\n","|  x|  y|  z|              source|      class|\n","+---+---+---+--------------------+-----------+\n","| 22| 49| 35|Accelerometer-201...|Brush_teeth|\n","| 22| 49| 35|Accelerometer-201...|Brush_teeth|\n","| 22| 52| 35|Accelerometer-201...|Brush_teeth|\n","| 22| 52| 35|Accelerometer-201...|Brush_teeth|\n","| 21| 52| 34|Accelerometer-201...|Brush_teeth|\n","| 22| 51| 34|Accelerometer-201...|Brush_teeth|\n","| 20| 50| 35|Accelerometer-201...|Brush_teeth|\n","| 22| 52| 34|Accelerometer-201...|Brush_teeth|\n","| 22| 50| 34|Accelerometer-201...|Brush_teeth|\n","| 22| 51| 35|Accelerometer-201...|Brush_teeth|\n","| 21| 51| 33|Accelerometer-201...|Brush_teeth|\n","| 20| 50| 34|Accelerometer-201...|Brush_teeth|\n","| 21| 49| 33|Accelerometer-201...|Brush_teeth|\n","| 21| 49| 33|Accelerometer-201...|Brush_teeth|\n","| 20| 51| 35|Accelerometer-201...|Brush_teeth|\n","| 18| 49| 34|Accelerometer-201...|Brush_teeth|\n","| 19| 48| 34|Accelerometer-201...|Brush_teeth|\n","| 16| 53| 34|Accelerometer-201...|Brush_teeth|\n","| 18| 52| 35|Accelerometer-201...|Brush_teeth|\n","| 18| 51| 32|Accelerometer-201...|Brush_teeth|\n","+---+---+---+--------------------+-----------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_dpnmTt3hIq7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":459},"outputId":"ad9bc518-5225-41a1-e775-a7c5fa46f330","executionInfo":{"status":"ok","timestamp":1585558197369,"user_tz":-480,"elapsed":4416,"user":{"displayName":"Harunobu Ishii","photoUrl":"","userId":"07995597585064114670"}}},"source":["from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, Normalizer, MinMaxScaler\n","from pyspark.ml.linalg import Vectors\n","from pyspark.ml import Pipeline\n","\n","indexer = StringIndexer(inputCol=\"class\", outputCol=\"classIndex\")\n","encoder = OneHotEncoder(inputCol=\"classIndex\", outputCol=\"categoryVec\")\n","vectorAssembler = VectorAssembler(inputCols=[\"x\",\"y\",\"z\"],\n","                                  outputCol=\"features\")\n","normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)\n","\n","minmaxscaler = MinMaxScaler(inputCol=\"features\", outputCol=\"features_minmax\")\n","\n","pipeline = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer, minmaxscaler])\n","model = pipeline.fit(df)\n","prediction = model.transform(df)\n","prediction.show()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+--------------------+\n","|  x|  y|  z|              source|      class|classIndex|   categoryVec|        features|       features_norm|     features_minmax|\n","+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+--------------------+\n","| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,49.0,35.0]|[0.20754716981132...|[0.34920634920634...|\n","| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,49.0,35.0]|[0.20754716981132...|[0.34920634920634...|\n","| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,35.0]|[0.20183486238532...|[0.34920634920634...|\n","| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,35.0]|[0.20183486238532...|[0.34920634920634...|\n","| 21| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,52.0,34.0]|[0.19626168224299...|[0.33333333333333...|\n","| 22| 51| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,51.0,34.0]|[0.20560747663551...|[0.34920634920634...|\n","| 20| 50| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,50.0,35.0]|[0.19047619047619...|[0.31746031746031...|\n","| 22| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,34.0]|[0.20370370370370...|[0.34920634920634...|\n","| 22| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,50.0,34.0]|[0.20754716981132...|[0.34920634920634...|\n","| 22| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,51.0,35.0]|[0.20370370370370...|[0.34920634920634...|\n","| 21| 51| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,51.0,33.0]|[0.2,0.4857142857...|[0.33333333333333...|\n","| 20| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,50.0,34.0]|[0.19230769230769...|[0.31746031746031...|\n","| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,49.0,33.0]|[0.20388349514563...|[0.33333333333333...|\n","| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,49.0,33.0]|[0.20388349514563...|[0.33333333333333...|\n","| 20| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,51.0,35.0]|[0.18867924528301...|[0.31746031746031...|\n","| 18| 49| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,49.0,34.0]|[0.17821782178217...|[0.28571428571428...|\n","| 19| 48| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[19.0,48.0,34.0]|[0.18811881188118...|[0.30158730158730...|\n","| 16| 53| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[16.0,53.0,34.0]|[0.15533980582524...|[0.25396825396825...|\n","| 18| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,52.0,35.0]|[0.17142857142857...|[0.28571428571428...|\n","| 18| 51| 32|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,51.0,32.0]|[0.17821782178217...|[0.28571428571428...|\n","+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+--------------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9ify4uVdn1Iz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":425},"outputId":"81a53174-e567-4f71-b021-59bd5506cc3e","executionInfo":{"status":"error","timestamp":1585559135282,"user_tz":-480,"elapsed":827,"user":{"displayName":"Harunobu Ishii","photoUrl":"","userId":"07995597585064114670"}}},"source":["from pyspark.ml.feature import  OneHotEncoderEstimator, StringIndexer, VectorAssembler, Normalizer, MinMaxScaler, OneHotEncoderEstimator\n","from pyspark.ml.linalg import Vectors\n","from pyspark.ml import Pipeline\n","\n","indexer = StringIndexer(inputCol=\"class\", outputCol=\"classIndex\")\n","encoder =  OneHotEncoderEstimator(inputCols=\"classIndex\", outputCols=\"categoryVec\")\n","vectorAssembler = VectorAssembler(inputCols=[\"x\",\"y\",\"z\"],\n","                                  outputCol=\"features\")\n","normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)\n","\n","\n","pipeline = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer])\n","model = pipeline.fit(df)\n","prediction = model.transform(df)\n","prediction.show()"],"execution_count":11,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/content/spark-2.4.5-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\u001b[0m in \u001b[0;36m_set\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-2.4.5-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\u001b[0m in \u001b[0;36mtoListString\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTypeConverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not convert %s to list of strings\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Could not convert classIndex to list of strings","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-b56607f3e33d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIndexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"classIndex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mOneHotEncoderEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"classIndex\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categoryVec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m vectorAssembler = VectorAssembler(inputCols=[\"x\",\"y\",\"z\"],\n\u001b[1;32m      8\u001b[0m                                   outputCol=\"features\")\n","\u001b[0;32m/content/spark-2.4.5-bin-hadoop2.7/python/pyspark/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-2.4.5-bin-hadoop2.7/python/pyspark/ml/feature.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputCols, outputCols, handleInvalid, dropLast)\u001b[0m\n\u001b[1;32m   1800\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setDefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandleInvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropLast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mkeyword_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-2.4.5-bin-hadoop2.7/python/pyspark/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-2.4.5-bin-hadoop2.7/python/pyspark/ml/feature.py\u001b[0m in \u001b[0;36msetParams\u001b[0;34m(self, inputCols, outputCols, handleInvalid, dropLast)\u001b[0m\n\u001b[1;32m   1810\u001b[0m         \"\"\"\n\u001b[1;32m   1811\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2.3.0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-2.4.5-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\u001b[0m in \u001b[0;36m_set\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid param value given for param \"%s\". %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_paramMap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Invalid param value given for param \"inputCols\". Could not convert classIndex to list of strings"]}]}]}